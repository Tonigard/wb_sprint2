# wb_sprint2_1

В данном репозитории решалась задача детекции мата в отзыве. Метрика для данной задачи была выбрана среднее расстояние Ливенштейна. Данная метрика измеряет количество операций вставки, удаления или замены, необходимых для преобразования одной строки в другую. Так же отдельно считалось расстояние Ливенштейна для случаев, где целевая метка не пустая. В качестве первого решения был выбран словарь, сформированный на основе разметки из исходного датасета. 
Метрика полученная на тестовой выборке
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.2|
|mean_distance_mat|1.44|

Далее был проанлизирован словарь и разметка в датасете. В ходе анализа выяснилось, что одни и те же слова в датасете размечены по разному, при похожем контексте. Было принято решение удалить из словаря те слова, которые были размечены чаще как «не мат». Это дало прирост к качеству. 
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.13|
|mean_distance_mat|1.03|

Так же был использован стеминг для этой задачи. Результат был значительно ухудшен.
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.94|
|mean_distance_mat|3.20|


Так же данная задача решалась как бинарная классификация токенов. В качестве модели был выбран «rubert». В данном эксперименте дополнительно отслеживались метрики f1, recall, precision, accuracy. Вторым экспериментом была изменена исходная разметка слов. Был использован словарь из предыдущих экспериментов, где были удалены слова, которые в разметке были чаще как «не мат». Этот эксперимент дал небольшой прирост, относительно первой моедли Bert

|Метрика | Значение|
-------------|-------------|
|mean_distance|0.36|
|mean_distance_mat|0.35|
|accuracy|0.00|
|f1|0.96|
|recall|0.97|
|precision|0.93|


