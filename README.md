## wb_sprint2_1

В данном репозитории решалась задача детекции мата в отзыве. Метрика для данной задачи была выбрана среднее расстояние Ливенштейна. Данная метрика измеряет количество операций вставки, удаления или замены, необходимых для преобразования одной строки в другую. Так же отдельно считалось расстояние Ливенштейна для случаев, где целевая метка не пустая. В качестве первого решения был выбран словарь, сформированный на основе разметки из исходного датасета. 
Метрика полученная на тестовой выборке
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.2|
|mean_distance_mat|1.44|

Далее был проанлизирован словарь и разметка в датасете. В ходе анализа выяснилось, что одни и те же слова в датасете размечены по разному, при похожем контексте. Было принято решение удалить из словаря те слова, которые были размечены чаще как «не мат». Это дало прирост к качеству. 
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.13|
|mean_distance_mat|1.03|

Так же был использован стеминг для этой задачи. Результат был значительно ухудшен.
|Метрика | Значение|
-------------|-------------|
|mean_distance|0.94|
|mean_distance_mat|3.20|


Так же данная задача решалась как бинарная классификация токенов. В качестве модели был выбран «rubert». В данном эксперименте дополнительно отслеживались метрики f1, recall, precision, accuracy. Вторым экспериментом была изменена исходная разметка слов. Был использован словарь из предыдущих экспериментов, где были удалены слова, которые в разметке были чаще как «не мат». Этот эксперимент дал небольшой прирост, относительно первой моедли Bert

|Метрика | Значение|
-------------|-------------|
|mean_distance|0.36|
|mean_distance_mat|2.45|
|accuracy|0.99|
|f1|0.96|
|recall|0.97|
|precision|0.93|

## wb_sprint2_2
Во второй части был ответ на вопрос. Как модель BERT определяет принадлежность слова к той или иной мтеки, если слово состоит из нескольких токенов. В первой части модель определяла метку слова по первому токену. Во вторай части, модель считала слово матом, если в ней есть хотя бы один токен, размеченный как мат. Это немного улучшило результат. 

|Метрика | Значение|
-------------|-------------|
|mean_distance|0.35|
|mean_distance_mat|2.39|
|accuracy|0.99|
|f1|0.95|
|recall|0.97|
|precision|0.93|

Создание словаря с помощью BPE. На вход строка с уникальными матными словами. Предполагается, что с помощью токезатора BPE можно получить самые частые комбинации символов, находящихся рядом друг с другом. Таким образом, можно было бы выявить некие паттерны матных слов. В качестве строки для обучения токеназатора подадим

|Метрика | Значение|
-------------|-------------|
|mean_distance|20.1|
|mean_distance_mat|22.2|

Заметим, что мтерики сильно ухудшились. Однако можно заметить, что данный метод имеет очень неплохой recall, но низкий precision. Это связано с тем, что объявленные патерны содержат элементы, которые встречаются и в обычных словах. При обучении модели BERT мы видим, что recall выше precision. При этом наш метод с BPE имеет тоже хороший отклик. А что, если сделать ансамбль из двух моделей, где первая будет выдавать свою метку на основе BERT, а вторая будет смотреть, содержит слово патерн из BPE

|Метрика | Значение|
-------------|-------------|
|mean_distance|0.19|
|mean_distance_mat|6.89|

Видим, сильное улучшение mean_distance. Однако при отправке ответа с тестовой выборкой в submission, резульатат был улучшем незначительно.
