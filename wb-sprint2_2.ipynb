{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":88517,"databundleVersionId":10312867,"sourceType":"competition"},{"sourceId":9802247,"sourceType":"datasetVersion","datasetId":6007770}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-Levenshtein\n!pip install clearml\n!pip install python-dotenv\n!pip install pymorphy2\n!pip install corus razdel\n!pip install datasets\n!pip install seqeval\n!pip install evaluate\n!pip install tokenizers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:31:14.693480Z","iopub.execute_input":"2025-01-19T09:31:14.694105Z","iopub.status.idle":"2025-01-19T09:32:36.577827Z","shell.execute_reply.started":"2025-01-19T09:31:14.694070Z","shell.execute_reply":"2025-01-19T09:32:36.576722Z"}},"outputs":[{"name":"stdout","text":"Collecting python-Levenshtein\n  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting Levenshtein==0.26.1 (from python-Levenshtein)\n  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\nSuccessfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.11.0\nCollecting clearml\n  Downloading clearml-1.17.0-py2.py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: attrs>=18.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (23.2.0)\nCollecting furl>=2.0.0 (from clearml)\n  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: jsonschema>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (4.22.0)\nRequirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.4)\nCollecting pathlib2>=2.3.0 (from clearml)\n  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: Pillow>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (10.3.0)\nRequirement already satisfied: psutil>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from clearml) (5.9.3)\nRequirement already satisfied: pyparsing>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from clearml) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.9.0.post0)\nRequirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.10/site-packages (from clearml) (6.0.2)\nRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.32.3)\nRequirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.16.0)\nRequirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from clearml) (1.26.18)\nRequirement already satisfied: pyjwt<2.10.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from clearml) (2.8.0)\nRequirement already satisfied: referencing<0.40 in /opt/conda/lib/python3.10/site-packages (from clearml) (0.35.1)\nCollecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (2023.12.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml) (0.18.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->clearml) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->clearml) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->clearml) (2024.8.30)\nDownloading clearml-1.17.0-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\nDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\nDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pathlib2, orderedmultidict, furl, clearml\nSuccessfully installed clearml-1.17.0 furl-2.1.3 orderedmultidict-1.0.1 pathlib2-2.3.7.post1\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\nCollecting pymorphy2\n  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\nCollecting dawg-python>=0.7.1 (from pymorphy2)\n  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\nCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\nDownloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\nDownloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\nSuccessfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\nCollecting corus\n  Downloading corus-0.10.0-py3-none-any.whl.metadata (31 kB)\nCollecting razdel\n  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\nDownloading corus-0.10.0-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading razdel-0.5.0-py3-none-any.whl (21 kB)\nInstalling collected packages: razdel, corus\nSuccessfully installed corus-0.10.0 razdel-0.5.0\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=97015275b9b20cba241786f49fa205d693ff6a7d1f222373f01e9b225fc9bcc9\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Решение задачи детекции мата с помощью cловаря","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tqdm import tqdm\nimport random\n\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom typing import List\nimport string\nimport os\nimport json\n\nfrom dotenv import load_dotenv\nfrom clearml import Task, OutputModel\nimport pickle\n\nimport Levenshtein\nfrom nltk.stem import PorterStemmer, SnowballStemmer\nimport pymorphy2\n\nfrom typing import Callable\n\n\nload_dotenv('/kaggle/input/dotenvs/.env.proj')\n\nAPI_ACCESS_KEY=os.environ.get('API_ACCESS_KEY')\nAPI_SECRET_KEY=os.environ.get('API_SECRET_KEY')\n\ndata = pd.read_csv(\"/kaggle/input/wildberries-winter-school-24-contest-detected/train.csv\")\ntest = pd.read_csv('/kaggle/input/wildberries-winter-school-24-contest-detected/test.csv')\ndata","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:36.580134Z","iopub.execute_input":"2025-01-19T09:32:36.580459Z","iopub.status.idle":"2025-01-19T09:32:45.438174Z","shell.execute_reply.started":"2025-01-19T09:32:36.580430Z","shell.execute_reply":"2025-01-19T09:32:45.437344Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            ID  \\\n0            0   \n1            1   \n2            2   \n3            3   \n4            4   \n...        ...   \n244734  248088   \n244735  248089   \n244736  248090   \n244737  248091   \n244738  248092   \n\n                                                                                                                                                                                                                                                                                            text  \\\n0                                                                                                                                                                                     брюки отличные, качественные, но к сожалению коротко ваты, поэтому отказ, обидно, продавца рекомендую всем   \n1                                                                                                                                                                                отличный аппарат, в комплекте кабель и работетт от сети , а значит можно сразу приступать к измерению давления.   \n2                                                                                                                                                                                                                                                                        супер 👍 спасибо большое   \n3                                                                                                                                                                                         получил быстро данные наушники! к наушникам пришёл прикольный чехол.  проблем с подключением не было 😇   \n4                                                                                                                                                                                                                                                             всё дошло в целости и сохранности)   \n...                                                                                                                                                                                                                                                                                          ...   \n244734                                                                                                                                                                                                                                                                       мне ее порвали суки   \n244735                                                                                                                                                                                                                                 Полное дерьмо, удалите этот товар и заблокируйте продавца   \n244736                                                                                                                                                                                                                                                                   Херня. Деньги на ветер.   \n244737  Это вообще что , за 💩 гов... ще?? Темнотища ужас!! Тонкая промашка 👎, рвётся, морщица и не расправляется, рисунок в некоторых местах не совпадает.. Еле от стены  отшкрябала, в полном смысле.  Стена новый гипсокартон, весь в краске покрасился🤦не рекомендую 👎👎👎👎 от слова СОВСЕМ!!!!   \n244738                                                                                                                  НЕ БЕРИТЕ!!!!! Мелкие, порезанные, подпорченные. Им цена 20 руб за всё. Отправлены в каком-то субстрате, пока не раскроешь, не увидишь какое там г... На ощупь не понять   \n\n            label  \n0             NaN  \n1             NaN  \n2             NaN  \n3             NaN  \n4             NaN  \n...           ...  \n244734       суки  \n244735     дерьмо  \n244736      херня  \n244737  гов... ще  \n244738   там г...  \n\n[244739 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>брюки отличные, качественные, но к сожалению коротко ваты, поэтому отказ, обидно, продавца рекомендую всем</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>отличный аппарат, в комплекте кабель и работетт от сети , а значит можно сразу приступать к измерению давления.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>супер 👍 спасибо большое</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>получил быстро данные наушники! к наушникам пришёл прикольный чехол.  проблем с подключением не было 😇</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>всё дошло в целости и сохранности)</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>244734</th>\n      <td>248088</td>\n      <td>мне ее порвали суки</td>\n      <td>суки</td>\n    </tr>\n    <tr>\n      <th>244735</th>\n      <td>248089</td>\n      <td>Полное дерьмо, удалите этот товар и заблокируйте продавца</td>\n      <td>дерьмо</td>\n    </tr>\n    <tr>\n      <th>244736</th>\n      <td>248090</td>\n      <td>Херня. Деньги на ветер.</td>\n      <td>херня</td>\n    </tr>\n    <tr>\n      <th>244737</th>\n      <td>248091</td>\n      <td>Это вообще что , за 💩 гов... ще?? Темнотища ужас!! Тонкая промашка 👎, рвётся, морщица и не расправляется, рисунок в некоторых местах не совпадает.. Еле от стены  отшкрябала, в полном смысле.  Стена новый гипсокартон, весь в краске покрасился🤦не рекомендую 👎👎👎👎 от слова СОВСЕМ!!!!</td>\n      <td>гов... ще</td>\n    </tr>\n    <tr>\n      <th>244738</th>\n      <td>248092</td>\n      <td>НЕ БЕРИТЕ!!!!! Мелкие, порезанные, подпорченные. Им цена 20 руб за всё. Отправлены в каком-то субстрате, пока не раскроешь, не увидишь какое там г... На ощупь не понять</td>\n      <td>там г...</td>\n    </tr>\n  </tbody>\n</table>\n<p>244739 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# фиксируем сид, для воиспрозводимости экспериментов\n\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:45.439422Z","iopub.execute_input":"2025-01-19T09:32:45.440042Z","iopub.status.idle":"2025-01-19T09:32:45.448447Z","shell.execute_reply.started":"2025-01-19T09:32:45.440000Z","shell.execute_reply":"2025-01-19T09:32:45.447771Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Настройка переменных окружения для подключение к clearml\n\nos.environ['CLEARML_WEB_HOST'] = 'https://app.clear.ml/'\nos.environ['CLEARML_API_HOST'] = 'https://api.clear.ml'\nos.environ['CLEARML_FILES_HOST'] = 'https://files.clear.ml'\nos.environ['CLEARML_API_ACCESS_KEY'] = f'{API_ACCESS_KEY}'\nos.environ['CLEARML_API_SECRET_KEY'] = f'{API_SECRET_KEY}'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:45.450297Z","iopub.execute_input":"2025-01-19T09:32:45.450559Z","iopub.status.idle":"2025-01-19T09:32:45.457965Z","shell.execute_reply.started":"2025-01-19T09:32:45.450533Z","shell.execute_reply":"2025-01-19T09:32:45.457288Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# загрузка объектов для процесинга слов (стеминг, лиматизация)\n\nmorph = pymorphy2.MorphAnalyzer()\nss = SnowballStemmer(language='russian')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:45.458857Z","iopub.execute_input":"2025-01-19T09:32:45.459121Z","iopub.status.idle":"2025-01-19T09:32:45.804394Z","shell.execute_reply.started":"2025-01-19T09:32:45.459082Z","shell.execute_reply":"2025-01-19T09:32:45.803690Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# формирование словаря мата из исходного датасета\n\ndata_train, data_test = train_test_split(data, test_size=0.2)\n\n\ndata_mat = data_train[~data_train['label'].isna()].copy()\nvocab = set()\nvocab_list = []\nfor text in tqdm(data_mat['label'], unit_scale=True):\n    for word in text.lower().split(','):\n        vocab.add(word.strip().lower())\n        vocab_list.append(word.strip().lower())\n        \nprint(f'Размер словаря: {len(vocab)}')\n\n\n# data_mat = data_train[~data_train['label'].isna()].copy()\n# vocab = set()\n# for text in tqdm(data_mat['label'], unit_scale=True):\n#     for word in text.split(','):\n#         vocab.add(word.strip().lower())\n        \n# print(f'Размер словаря до стеминга: {len(vocab)}')\n# vocab = set(list(map(ss.stem, vocab)))\n# print(f'Размер словаря после стеминга: {len(vocab)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:45.805489Z","iopub.execute_input":"2025-01-19T09:32:45.805728Z","iopub.status.idle":"2025-01-19T09:32:45.899011Z","shell.execute_reply.started":"2025-01-19T09:32:45.805702Z","shell.execute_reply":"2025-01-19T09:32:45.898198Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 27.9k/27.9k [00:00<00:00, 686kit/s]","output_type":"stream"},{"name":"stdout","text":"Размер словаря: 3180\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def analysis(data: pd.DataFrame, vocab: set, processing=None) -> pd.DataFrame:\n    \"\"\"\n    Данная фнукция подсчитывает сколько раз каждое слово в словаре является и/или\n    не является матом в исходном датафрейме\n    \"\"\"\n    analys = {word: [0, 0] for word in vocab}\n    \n    for i, row in tqdm(data.iterrows(), unit_scale=True):\n        prccessed_text = row['text'].lower().translate(\n            str.maketrans('', '', string.punctuation))\n        words_in_text = prccessed_text.strip().split()\n\n        if processing == 'staming':\n            words_in_text = list(map(ss.stem, words_in_text))\n        \n        for word in words_in_text:\n            con = row['label'] is not np.nan\n            if con and word in vocab and word in row['label'].split(','):\n                analys[word][0] += 1\n            elif word in vocab:\n                analys[word][1] += 1\n\n    df = pd.DataFrame.from_dict(analys, orient='index', columns=['count_like_mat', 'count_not_mat'])\n    \n    return df\n\nanalys_df = analysis(data, vocab)\n\n# таблица со словами, которые были размечены по-разному \nanalys_df[analys_df['count_not_mat'] > 0 & analys_df['count_like_mat']].sort_values('count_not_mat', ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:32:45.900305Z","iopub.execute_input":"2025-01-19T09:32:45.900668Z","iopub.status.idle":"2025-01-19T09:33:07.794987Z","shell.execute_reply.started":"2025-01-19T09:32:45.900627Z","shell.execute_reply":"2025-01-19T09:33:07.794092Z"}},"outputs":[{"name":"stderr","text":"245kit [00:21, 11.2kit/s] \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"            count_like_mat  count_not_mat\nполное                   0           3970\nтакое                    1           2762\nг                      125           2195\nхрень                    7           1111\nх                        3            376\n...                    ...            ...\nауенная                  1              1\nохуенно                 49              1\nпизданул                 2              1\nзадолбался              61              1\nкнчл                     1              1\n\n[397 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count_like_mat</th>\n      <th>count_not_mat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>полное</th>\n      <td>0</td>\n      <td>3970</td>\n    </tr>\n    <tr>\n      <th>такое</th>\n      <td>1</td>\n      <td>2762</td>\n    </tr>\n    <tr>\n      <th>г</th>\n      <td>125</td>\n      <td>2195</td>\n    </tr>\n    <tr>\n      <th>хрень</th>\n      <td>7</td>\n      <td>1111</td>\n    </tr>\n    <tr>\n      <th>х</th>\n      <td>3</td>\n      <td>376</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ауенная</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>охуенно</th>\n      <td>49</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>пизданул</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>задолбался</th>\n      <td>61</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>кнчл</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>397 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# формирование списка слов, которые были размечены чаще как не мат\n# для последующего удаления\n\ntemp_df = analys_df[analys_df['count_not_mat'] > 0 & analys_df['count_like_mat']].copy()\ndelete_words = temp_df[temp_df['count_not_mat'] > temp_df['count_like_mat']].index\ndelete_words = delete_words.tolist()\nprint(f\"Количество слов для удаления {len(delete_words)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:33:07.796097Z","iopub.execute_input":"2025-01-19T09:33:07.796374Z","iopub.status.idle":"2025-01-19T09:33:07.802912Z","shell.execute_reply.started":"2025-01-19T09:33:07.796348Z","shell.execute_reply":"2025-01-19T09:33:07.801949Z"}},"outputs":[{"name":"stdout","text":"Количество слов для удаления 118\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# облако слов\n\nwc = WordCloud(background_color=\"white\", max_words=200, margin=5,\n               min_font_size=20, random_state=seed_val, colormap='summer')\nwc.generate(data_train.label[(data_train.label.notnull())].to_string())\nplt.figure(figsize=(20, 10))\nplt.title(\"Облако слов\")\nplt.axis(\"off\")\nplt.imshow(wc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:33:07.804031Z","iopub.execute_input":"2025-01-19T09:33:07.804341Z","iopub.status.idle":"2025-01-19T09:33:08.807866Z","shell.execute_reply.started":"2025-01-19T09:33:07.804315Z","shell.execute_reply":"2025-01-19T09:33:08.807007Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7ebd0b8697e0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 2000x1000 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def find_words_in_string(vocab: set, text: str, processing=None) -> list:\n    \"\"\"\n    Данная функция находит находит слова из словаря в строке и возращает\n    отсортированный список найденных слов.\n    \"\"\"\n    # Преобразуем текст в нижний регистр и разбиваем его на слова\n    prccessed_text = text.lower().translate(\n        str.maketrans('', '', string.punctuation))\n    words_in_text = prccessed_text.lower().strip().split()\n    \n    if processing == 'staming':\n        words_in_text_proc = list(map(ss.stem, words_in_text))\n    elif processing == 'limatization':\n        words_in_text_proc = list(map(lambda x: morph.parse(x)[0].normal_form, words_in_text))\n    else:\n        words_in_text_proc = words_in_text\n\n    positions = {}\n    \n    for index, word in enumerate(words_in_text_proc):\n        if word in vocab:\n            positions[word] = index\n\n    return sorted([words_in_text[value] for value in positions.values()])\n\ndef find_patterns_in_words(patterns: set, text: str, processing=None) -> list:\n    \"\"\"\n    Данная функция нужна для поиска слов в тексте, которые содержат определенные патерны.\n    Возвращает отсортированный список найденных слов.\n    \"\"\"\n    prccessed_text = text.lower().translate(\n        str.maketrans('', '', string.punctuation)\n    )\n    words_in_text = prccessed_text.lower().strip().split()\n    \n    if processing == 'staming':\n        words_in_text_proc = list(map(ss.stem, words_in_text))\n    elif processing == 'limatization':\n        words_in_text_proc = list(map(lambda x: morph.parse(x)[0].normal_form, words_in_text))\n    else:\n        words_in_text_proc = words_in_text\n\n    positions = {}\n    \n    for index, word in enumerate(words_in_text_proc):\n        for pattern in patterns:\n            if pattern in word:\n                positions[word] = index\n                \n\n    return sorted([words_in_text[value] for value in positions.values()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:33:08.810334Z","iopub.execute_input":"2025-01-19T09:33:08.810616Z","iopub.status.idle":"2025-01-19T09:33:08.819003Z","shell.execute_reply.started":"2025-01-19T09:33:08.810589Z","shell.execute_reply":"2025-01-19T09:33:08.818211Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# удаляем слова, которые ошибочно были занесены в словарь \n\ndelete_words = ['полное', 'г', 'го', 'хрень', 'х'] + delete_words\ndelete_words_json = json.dumps(delete_words, ensure_ascii=False)\nfor word in delete_words:\n    try:\n        vocab.remove(word)\n    except: continue\n\n# delete_words = ['полное', 'полная', 'просто', 'простое', \n#                 'простой' 'г', 'го', 'хрень', 'х', 'на']\n# delete_words_json = json.dumps(delete_words, ensure_ascii=False)\n# for word in delete_words:\n#     try:\n#         vocab.remove(word)\n#     except: continue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:33:08.820379Z","iopub.execute_input":"2025-01-19T09:33:08.820752Z","iopub.status.idle":"2025-01-19T09:33:08.832824Z","shell.execute_reply.started":"2025-01-19T09:33:08.820681Z","shell.execute_reply":"2025-01-19T09:33:08.832052Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def test_review(vocab: set, find_mat: Callable, processing=None) -> dict:\n    \"\"\"\n    Данная функция рассчитывает расстояние Левенштейна между таргет строкой и \n    предсказанной строкой, сформированной на основе словаря, и возвращает\n    среднее расстояние Левенштейна и ошибки, получившиеся в результате \n    неверных предсказаний\n    \"\"\"\n    mistakes = {}\n    distance = 0\n    distance_mat = 0\n    \n    for i, row in tqdm(data_test.iterrows(), unit_scale=True):\n        found_words = \",\".join(find_mat(vocab, row['text'], processing))\n        label = row['label'] if row['label'] is not np.nan else ''\n        current_distance = Levenshtein.distance(found_words, label)\n        distance += current_distance\n\n        if row['label'] is not np.nan:\n            if i < 500:\n                print(\"Найденные слова: \", found_words)\n                print(\"Метка: \", row['label'])\n                print()\n            current_distance_mat =  Levenshtein.distance(found_words, label)\n            distance_mat += current_distance_mat\n        \n        if current_distance > 0:\n            if row['label'] not in mistakes.keys():\n                mistakes[row['label']] = [found_words, current_distance]\n            else:\n                mistakes[row['label']] += [found_words, current_distance]\n\n    mean_distance = distance / len(data_test)\n    mean_distance_mat = distance_mat / len(data_test[~data_test['label'].isna()])\n    \n    return mistakes, mean_distance, mean_distance_mat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T10:03:11.166652Z","iopub.execute_input":"2025-01-19T10:03:11.166999Z","iopub.status.idle":"2025-01-19T10:03:11.174804Z","shell.execute_reply.started":"2025-01-19T10:03:11.166965Z","shell.execute_reply":"2025-01-19T10:03:11.173972Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# # создание и логирование эксперимента\n\n# task1 = Task.init(project_name='wb sprint2', task_name='vocab from dataset')\nmistakes, mean_distance, mean_distance_mat = test_review(vocab, find_words_in_string)\nprint(f\"Среднее расстояние Леветштейна: {mean_distance}\")\nprint(f\"Среднее расстояние Леветштейна для непустых label: {mean_distance_mat}\")\n# task1.connect({\n#     'vocab': 'vocab from dataset all data',\n#     'vocab_size': len(vocab),\n#     'mean_distance': mean_distance,\n#     'mean_distance_mat': mean_distance_mat,\n#     'delete words': delete_words_json,\n#     'processing': '-'\n# })\n\n# mistakes_path = '/kaggle/working/mistakes.pkl'\n# with open(mistakes_path, 'wb') as f:\n#     pickle.dump(mistakes, f)\n\n# vocab_path = '/kaggle/working/vocab.json'\n# with open(vocab_path, 'w', encoding='utf-8') as f:\n#     json.dump(list(vocab), f, ensure_ascii=False)\n\n# task1.upload_artifact('mistakes', artifact_object='/kaggle/working/mistakes.pkl')\n# task1.upload_artifact('vocab', artifact_object=vocab_path)\n# task1.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:33:08.845606Z","iopub.execute_input":"2025-01-19T09:33:08.845929Z","iopub.status.idle":"2025-01-19T09:33:12.203607Z","shell.execute_reply.started":"2025-01-19T09:33:08.845889Z","shell.execute_reply":"2025-01-19T09:33:12.202676Z"}},"outputs":[{"name":"stderr","text":"48.9kit [00:03, 14.7kit/s]","output_type":"stream"},{"name":"stdout","text":"Среднее расстояние Леветштейна: 0.3089196698537223\nСреднее расстояние Леветштейна для непустых label: 2.1596095880579878\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# # вывод самых частых ошибок \n\n# sorted_keys = sorted(mistakes, key=lambda k: len(mistakes[k]), reverse=True)\n\n# # Выбираем первые 5 ключей\n# top_5_keys = sorted_keys[:5]\n\n# print(\"Ключи с самыми длинными значениями:\", top_5_keys)\n# print(\"Самые длинные значения:\", [mistakes[key] for key in top_5_keys])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T22:20:44.956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # тест модели\n\n# previous_task_id = '7e9906757e204991ae08ca0ed3e142a1'  # Замените на ID вашего предыдущего эксперимента\n# previous_task = Task.get_task(task_id=previous_task_id)\n\n# vocab_artifact = previous_task.artifacts['vocab']\n# vocab_path = vocab_artifact.get_local_copy()\n# with open(vocab_path, 'rb') as f:\n#     vocab = set(json.load(f))\n\n# label = []\n# for i, row in tqdm(test.iterrows(), unit_scale=True):\n#     found_words = \",\".join(find_words_in_string(vocab, row['text']))\n#     label.append(found_words)\n\n# answer = test.copy().drop('text', axis=1)\n# answer['label'] = label\n# answer.to_csv('answer.csv', index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T22:20:44.956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Создание словаря с помощью BPE. На вход строка с уникальными матными словами","metadata":{}},{"cell_type":"markdown","source":"Предполагается, что с помощью токезатора BPE можно получить самые частые комбинации символов, находящихся рядом друг с другом. Таким образом, можно было бы выявить некие паттерны матных слов. В качестве строки для обучения токеназатора подадим ","metadata":{}},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\n\n\nmat_uniq = \" \".join(vocab_list)\n\nwith open(\"mat_uniq.txt\", \"w\") as f:\n    f.write(mat_uniq)\n\ntokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\ntrainer = BpeTrainer(special_tokens=[\"[UNK]\"], min_frequency=20, vocab_size=400)\ntokenizer.train([\"mat_uniq.txt\"], trainer)\noutput = tokenizer.encode(\"пиздец нахуй бля асаламу\")\nprint(output.tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:51:03.649700Z","iopub.execute_input":"2025-01-19T09:51:03.650521Z","iopub.status.idle":"2025-01-19T09:51:11.989668Z","shell.execute_reply.started":"2025-01-19T09:51:03.650483Z","shell.execute_reply":"2025-01-19T09:51:11.988804Z"}},"outputs":[{"name":"stdout","text":"\n\n\n['пизд', 'ец', ' нахуй', ' бля', ' а', 'с', 'ал', 'а', 'м', 'у']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Необходимо удалить из токенезатора символы размером 1-2, так как они не похоже на паттерны мата","metadata":{}},{"cell_type":"code","source":"# Смотрим статистику по длине матных слов, чтобы убедиться, что мы не удалим\n# много лишних паттернов\n\nnp_arr = pd.Series([len(i) for i in vocab_list])\nprint(np_arr.describe())\nprint(\"Количество матных слов длинной 2: \", len(np_arr[np_arr == 2]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:51:11.991128Z","iopub.execute_input":"2025-01-19T09:51:11.991436Z","iopub.status.idle":"2025-01-19T09:51:12.011122Z","shell.execute_reply.started":"2025-01-19T09:51:11.991408Z","shell.execute_reply":"2025-01-19T09:51:12.010210Z"}},"outputs":[{"name":"stdout","text":"count    31950.000000\nmean         5.677715\nstd          1.836952\nmin          0.000000\n25%          5.000000\n50%          5.000000\n75%          6.000000\nmax         39.000000\ndtype: float64\nКоличество матных слов длинной 2:  248\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"Длина исходного словаря токеназатора: \", len(tokenizer.get_vocab().items()))\nmin_token_length = 3\nfiltered = {token.strip(): idx for token, idx in tokenizer.get_vocab().items() if len(token.strip()) >= min_token_length}\nfiltered_vocab = set(filtered.keys())\nprint(\"Длина отфильтрованного словаря токеназатора: \", len(filtered_vocab))\nprint(\"Отфильтрованный словарь: \", filtered_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T09:51:43.293124Z","iopub.execute_input":"2025-01-19T09:51:43.293502Z","iopub.status.idle":"2025-01-19T09:51:43.300127Z","shell.execute_reply.started":"2025-01-19T09:51:43.293470Z","shell.execute_reply":"2025-01-19T09:51:43.299283Z"}},"outputs":[{"name":"stdout","text":"Длина исходного словаря токеназатора:  400\nДлина отфильтрованного словаря токеназатора:  189\nОтфильтрованный словарь:  {'ебан', 'сука', 'ись', 'херня дерьмо', 'ась', 'хер', 'ебал', 'задниц', 'жопе', 'педи', 'чмо', 'нахуй', 'рукожопы', 'дерьмо', 'ахуе', 'заебок', 'херня говно', 'суки', 'говно дерьмо', 'заебись', 'изд', 'херня гавно', 'хуй', 'блять', 'гомно', 'нти', 'говно высер', 'конч', 'говно еб', 'дерьмо гавно', 'говно на', 'гавно дерьмо', 'нтин', 'ахуен', 'пер', 'дер', 'хуе', 'херня херня', 'ные', 'хулиг', 'нихуя', 'х..', 'раз', 'хули', 'нище', 'дерьмо дерьмо', 'хера', 'пиздатые', 'пизда', 'гавно', 'пиздец', 'бля', 'сук', 'зад', 'обос', 'говно говн', 'наебал', 'хулиган', 'полное', 'заеба', 'пиздили', 'тая', 'хует', 'дермо', 'ахуй', 'пиздато', 'ебаная', 'пидо', 'пзд', 'тра', 'жопа', 'г.... г...', 'ень', 'бляха', 'мно', 'г....', 'залупа', 'г...но', 'збс', 'итель', 'пиздатая', 'говно хуйня', '...', 'жопы', 'вахуе', 'пздц', 'говнище', 'дерьмище', 'проебал', 'пизд', 'г....о', 'охуен', 'гов', 'дерь', 'г..... г.... г...', 'дерьмо говно', 'луп', 'жопу', 'говно рукожоп', 'хуета', 'высер', 'рал', 'залуп', 'дерьмо херня', 'дерьма', 'задолбалась', 'говно о', 'про', 'ожоп', 'говно гавно', 'задолб', 'гавно гавно', 'рукожоп', 'нахер', 'кончен', 'задолбал', 'ано', 'говно жоп', 'хуи', 'задолбали', 'наеб', 'аху', 'гавно херня', 'говно херня', 'гавно говно', 'ъеб', 'г..', 'задница', 'херня', 'жоп', 'херню', 'трах', 'говно', 'ндо', 'х...', 'гав', 'г...о г...', 'хуя', 'говна', 'ахуенные', 'херо', 'ниц', 'еба', 'ать', 'ебу', 'говном', 'г.....', 'рас', 'пизди', '[UNK]', 'ски', 'гамно', 'срал', 'ный', 'ахуенная', 'дерьм', 'олб', 'ель', 'ахуенны', 'вать', 'заеб', 'неебу', 'хуйня', 'ное', 'вый', 'г...', 'сер', 'перд', 'ище', 'заднице', 'оху', 'ахуенно', 'пол', 'говно говно', 'ахуенный', 'говно бля', 'йня', 'говн', 'пиздат', 'вно', 'г...о', 'говно бл', 'сра', 'рук', 'долб', 'херь', 'нихера', 'ная', 'блях'}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"output = tokenizer.encode(\"довольный\")\nprint(output.tokens)\n# filtered_vocab = {'пизд', 'охуен', 'йня', 'заебись', 'говно'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:53:07.836500Z","iopub.execute_input":"2025-01-18T14:53:07.837080Z","iopub.status.idle":"2025-01-18T14:53:07.844194Z","shell.execute_reply.started":"2025-01-18T14:53:07.837015Z","shell.execute_reply":"2025-01-18T14:53:07.843206Z"}},"outputs":[{"name":"stdout","text":"['до', 'в', 'ол', 'ь', 'ный']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# создание и логирование эксперимента find_patterns_in_words find_words_in_string\n\n#task1 = Task.init(project_name='wb sprint2', task_name='vocab with BPE unique')\nmistakes, mean_distance, mean_distance_mat = test_review(filtered_vocab, find_patterns_in_words)\nprint(f\"Среднее расстояние Леветштейна: {mean_distance}\")\nprint(f\"Среднее расстояние Леветштейна для непустых label: {mean_distance_mat}\")\n# task1.connect({\n#     'vocab': 'vocab from dataset all data',\n#     'vocab_size': len(filtered_vocab),\n#     'mean_distance': mean_distance,\n#     'mean_distance_mat': mean_distance_mat,\n#     'delete words': '',\n#     'processing': '-',\n#     'using tokenizer to split': 'False'\n# })\n\n# mistakes_path = '/kaggle/working/mistakes.pkl'\n# with open(mistakes_path, 'wb') as f:\n#     pickle.dump(mistakes, f)\n\n# vocab_path = '/kaggle/working/vocab.json'\n# with open(vocab_path, 'w', encoding='utf-8') as f:\n#     json.dump(list(vocab), f, ensure_ascii=False)\n\n# task1.upload_artifact('mistakes', artifact_object='/kaggle/working/mistakes.pkl')\n# task1.upload_artifact('vocab', artifact_object=vocab_path)\n# task1.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T10:03:19.466560Z","iopub.execute_input":"2025-01-19T10:03:19.466892Z","iopub.status.idle":"2025-01-19T10:03:30.883096Z","shell.execute_reply.started":"2025-01-19T10:03:19.466864Z","shell.execute_reply":"2025-01-19T10:03:30.882193Z"}},"outputs":[{"name":"stderr","text":"3.44kit [00:00, 4.25kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  говно,держит,полное,пройдите,просто,трепать\nМетка:  говно\n\nНайденные слова:  говно,гораздо,деньги,использования,обычный,оказалась,очень,первого,промокла,размер,размеры,разочарован\nМетка:  говно\n\n","output_type":"stream"},{"name":"stderr","text":"11.0kit [00:02, 4.25kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  отпиздили\nМетка:  отпиздили\n\n","output_type":"stream"},{"name":"stderr","text":"12.7kit [00:02, 4.33kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  говно,день,полное\nМетка:  говно\n\n","output_type":"stream"},{"name":"stderr","text":"14.1kit [00:03, 4.32kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  херабора\nМетка:  херабора\n\n","output_type":"stream"},{"name":"stderr","text":"18.0kit [00:04, 4.31kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  браслета,день,ебаная,залупа,первый,хуй,хуйня\nМетка:  залупа,ебаная,хуйня\n\n","output_type":"stream"},{"name":"stderr","text":"28.2kit [00:06, 4.41kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  водный,дохера,концнлярский,хрень,черный\nМетка:  дохера\n\n","output_type":"stream"},{"name":"stderr","text":"34.7kit [00:08, 4.08kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  говно\nМетка:  говно\n\n","output_type":"stream"},{"name":"stderr","text":"43.3kit [00:10, 4.20kit/s]","output_type":"stream"},{"name":"stdout","text":"Найденные слова:  говно,очень,полторы,продаете,серьезно\nМетка:  говно,высер,говн\n\n","output_type":"stream"},{"name":"stderr","text":"48.9kit [00:11, 4.29kit/s]","output_type":"stream"},{"name":"stdout","text":"Среднее расстояние Леветштейна: 20.133141292800524\nСреднее расстояние Леветштейна для непустых label: 22.14970575570547\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Можно заметить, что данный метод имеет очень неплохой recall, но низкий precision. Это связано с тем, что объявленные патерны содержат элементы, которые встречаются и в обычных словах.","metadata":{}},{"cell_type":"markdown","source":"### Решение задачи детекции мата с помощью обучения модели Bert для задачи классификации токенов","metadata":{}},{"cell_type":"code","source":"import datasets \nfrom datasets import Dataset, DatasetDict\nimport numpy as np\n\nfrom transformers import BertTokenizerFast \nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorForTokenClassification\nimport evaluate\n\n\nimport re\nfrom razdel import tokenize\n\nimport logging\nfrom transformers.trainer import logger as noisy_logger\nimport joblib\n\n\nnoisy_logger.setLevel(logging.WARNING)\n\ndef remove_emoji(text) -> str:\n    \"\"\"\n    удаляет ээмоджи из строки\n    \"\"\"\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nprint(remove_emoji('👍!'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:53:12.492557Z","iopub.execute_input":"2025-01-18T14:53:12.493463Z","iopub.status.idle":"2025-01-18T14:53:27.741942Z","shell.execute_reply.started":"2025-01-18T14:53:12.493425Z","shell.execute_reply":"2025-01-18T14:53:27.741066Z"}},"outputs":[{"name":"stdout","text":"!\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# скачивание обученного токенайзера\n\nmodel_checkpoint = \"cointegrated/rubert-tiny\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:29:28.952060Z","iopub.execute_input":"2025-01-18T16:29:28.952415Z","iopub.status.idle":"2025-01-18T16:29:29.081663Z","shell.execute_reply.started":"2025-01-18T16:29:28.952384Z","shell.execute_reply":"2025-01-18T16:29:29.080707Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning:\n\n`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# разбиение текста на токены и разметка токенов на классы\n\ntags = []\ntokens = []\nfor i, row in tqdm(data.iterrows(), unit_scale=True):\n    prccessed_text = remove_emoji(row['text']).lower()\n    raw_toks = tokenizer.tokenize(prccessed_text)\n    words = []\n    current_word = \"\"\n    for token in raw_toks:\n        if token.startswith(\"##\"):\n            current_word += token[2:]\n        else:\n            if current_word:\n                words.append(current_word)\n            current_word = token\n    if current_word:\n        words.append(current_word)\n    tokens.append(words)\n    mat = row['label']\n    if mat is not np.nan:\n        tags.append(['O' if word not in mat.split(',') else 'M' if word in vocab\n                     else 'O' for word in words])\n    else:\n        tags.append(['O' for word in words])\n    \ndata['tags'] = tags\ndata['tokens'] = tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:53:28.486698Z","iopub.execute_input":"2025-01-18T14:53:28.487376Z","iopub.status.idle":"2025-01-18T14:54:34.751860Z","shell.execute_reply.started":"2025-01-18T14:53:28.487333Z","shell.execute_reply":"2025-01-18T14:54:34.751182Z"}},"outputs":[{"name":"stderr","text":"4.06kit [00:01, 3.40kit/s]Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n245kit [01:06, 3.70kit/s] \n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"data[~data['label'].isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T12:46:35.785613Z","iopub.execute_input":"2025-01-18T12:46:35.786095Z","iopub.status.idle":"2025-01-18T12:46:35.839747Z","shell.execute_reply.started":"2025-01-18T12:46:35.786058Z","shell.execute_reply":"2025-01-18T12:46:35.838620Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"            ID  \\\n32          32   \n36          36   \n39          39   \n53          53   \n58          58   \n...        ...   \n244734  248088   \n244735  248089   \n244736  248090   \n244737  248091   \n244738  248092   \n\n                                                                                                                                                                                                                                                                                            text  \\\n32                                                                                                                                                                                                                                                                              говно а не товар   \n36                                                                                                                  спасибо за уёбищние шарики!такой хуйни я еще не видела!спасибо за испорченое настроение!у вас больше никогда в жизни не куплю,и другим не советую,даже одной звезды вам мало   \n39                                                                                                                                                                                                                                                     пришла какая-то х....та вы там чё курите?   \n53                                                                                                                                                                                                                                                    полное говно, не липнет пустая трата денег   \n58                                                                                                                                                                на вид очень даже ничего. но хочу сказать, что по качеству полное г... прислали еще и грязную. заявленную цену оно не стоит. 🤔   \n...                                                                                                                                                                                                                                                                                          ...   \n244734                                                                                                                                                                                                                                                                       мне ее порвали суки   \n244735                                                                                                                                                                                                                                 Полное дерьмо, удалите этот товар и заблокируйте продавца   \n244736                                                                                                                                                                                                                                                                   Херня. Деньги на ветер.   \n244737  Это вообще что , за 💩 гов... ще?? Темнотища ужас!! Тонкая промашка 👎, рвётся, морщица и не расправляется, рисунок в некоторых местах не совпадает.. Еле от стены  отшкрябала, в полном смысле.  Стена новый гипсокартон, весь в краске покрасился🤦не рекомендую 👎👎👎👎 от слова СОВСЕМ!!!!   \n244738                                                                                                                  НЕ БЕРИТЕ!!!!! Мелкие, порезанные, подпорченные. Им цена 20 руб за всё. Отправлены в каком-то субстрате, пока не раскроешь, не увидишь какое там г... На ощупь не понять   \n\n                 label  \\\n32               говно   \n36      уёбищние,хуйни   \n39                х...   \n53               говно   \n58                г...   \n...                ...   \n244734            суки   \n244735          дерьмо   \n244736           херня   \n244737       гов... ще   \n244738        там г...   \n\n                                                                                                                                                                                     tags  \\\n32                                                                                                                                                                           [M, O, O, O]   \n36                                                                           [O, O, M, O, O, O, M, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n39                                                                                                                                          [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n53                                                                                                                                                               [O, M, O, O, O, O, O, O]   \n58                                                                                                [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n...                                                                                                                                                                                   ...   \n244734                                                                                                                                                                       [O, O, O, M]   \n244735                                                                                                                                                        [O, M, O, O, O, O, O, O, O]   \n244736                                                                                                                                                                 [M, O, O, O, O, O]   \n244737  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n244738                                                  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n\n                                                                                                                                                                                                                                                                                                                                                             tokens  \n32                                                                                                                                                                                                                                                                                                                                            [говно, а, не, товар]  \n36                                                                                                                                      [спасибо, за, уёбищние, шарики, !, такой, хуйни, я, еще, не, видела, !, спасибо, за, испорченое, настроение, !, у, вас, больше, никогда, в, жизни, не, куплю, ,, и, другим, не, советую, ,, даже, одной, звезды, вам, мало]  \n39                                                                                                                                                                                                                                                                                                [пришла, какая, -, то, х, ., ., ., ., та, вы, там, чё, курите, ?]  \n53                                                                                                                                                                                                                                                                                                             [полное, говно, ,, не, липнет, пустая, трата, денег]  \n58                                                                                                                                                                                                [на, вид, очень, даже, ничего, ., но, хочу, сказать, ,, что, по, качеству, полное, г, ., ., ., прислали, еще, и, грязную, ., заявленную, цену, оно, не, стоит, .]  \n...                                                                                                                                                                                                                                                                                                                                                             ...  \n244734                                                                                                                                                                                                                                                                                                                                     [мне, ее, порвали, суки]  \n244735                                                                                                                                                                                                                                                                                         [полное, дерьмо, ,, удалите, этот, товар, и, заблокируйте, продавца]  \n244736                                                                                                                                                                                                                                                                                                                             [херня, ., деньги, на, ветер, .]  \n244737  [это, вообще, что, ,, за, гов, ., ., ., ще, ?, ?, темнотища, ужас, !, !, тонкая, промашка, ,, рвётся, ,, морщица, и, не, расправляется, ,, рисунок, в, некоторых, местах, не, совпадает, ., ., еле, от, стены, отшкрябала, ,, в, полном, смысле, ., стена, новый, гипсокартон, ,, весь, в, краске, покрасилсяне, рекомендую, от, слова, совсем, !, !, !, !]  \n244738                                                                                                                         [не, берите, !, !, !, !, !, мелкие, ,, порезанные, ,, подпорченные, ., им, цена, 20, руб, за, всё, ., отправлены, в, каком, -, то, субстрате, ,, пока, не, раскроешь, ,, не, увидишь, какое, там, г, ., ., ., на, ощупь, не, понять]  \n\n[34851 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>text</th>\n      <th>label</th>\n      <th>tags</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>говно а не товар</td>\n      <td>говно</td>\n      <td>[M, O, O, O]</td>\n      <td>[говно, а, не, товар]</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>спасибо за уёбищние шарики!такой хуйни я еще не видела!спасибо за испорченое настроение!у вас больше никогда в жизни не куплю,и другим не советую,даже одной звезды вам мало</td>\n      <td>уёбищние,хуйни</td>\n      <td>[O, O, M, O, O, O, M, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[спасибо, за, уёбищние, шарики, !, такой, хуйни, я, еще, не, видела, !, спасибо, за, испорченое, настроение, !, у, вас, больше, никогда, в, жизни, не, куплю, ,, и, другим, не, советую, ,, даже, одной, звезды, вам, мало]</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>пришла какая-то х....та вы там чё курите?</td>\n      <td>х...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[пришла, какая, -, то, х, ., ., ., ., та, вы, там, чё, курите, ?]</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>53</td>\n      <td>полное говно, не липнет пустая трата денег</td>\n      <td>говно</td>\n      <td>[O, M, O, O, O, O, O, O]</td>\n      <td>[полное, говно, ,, не, липнет, пустая, трата, денег]</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>58</td>\n      <td>на вид очень даже ничего. но хочу сказать, что по качеству полное г... прислали еще и грязную. заявленную цену оно не стоит. 🤔</td>\n      <td>г...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[на, вид, очень, даже, ничего, ., но, хочу, сказать, ,, что, по, качеству, полное, г, ., ., ., прислали, еще, и, грязную, ., заявленную, цену, оно, не, стоит, .]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>244734</th>\n      <td>248088</td>\n      <td>мне ее порвали суки</td>\n      <td>суки</td>\n      <td>[O, O, O, M]</td>\n      <td>[мне, ее, порвали, суки]</td>\n    </tr>\n    <tr>\n      <th>244735</th>\n      <td>248089</td>\n      <td>Полное дерьмо, удалите этот товар и заблокируйте продавца</td>\n      <td>дерьмо</td>\n      <td>[O, M, O, O, O, O, O, O, O]</td>\n      <td>[полное, дерьмо, ,, удалите, этот, товар, и, заблокируйте, продавца]</td>\n    </tr>\n    <tr>\n      <th>244736</th>\n      <td>248090</td>\n      <td>Херня. Деньги на ветер.</td>\n      <td>херня</td>\n      <td>[M, O, O, O, O, O]</td>\n      <td>[херня, ., деньги, на, ветер, .]</td>\n    </tr>\n    <tr>\n      <th>244737</th>\n      <td>248091</td>\n      <td>Это вообще что , за 💩 гов... ще?? Темнотища ужас!! Тонкая промашка 👎, рвётся, морщица и не расправляется, рисунок в некоторых местах не совпадает.. Еле от стены  отшкрябала, в полном смысле.  Стена новый гипсокартон, весь в краске покрасился🤦не рекомендую 👎👎👎👎 от слова СОВСЕМ!!!!</td>\n      <td>гов... ще</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[это, вообще, что, ,, за, гов, ., ., ., ще, ?, ?, темнотища, ужас, !, !, тонкая, промашка, ,, рвётся, ,, морщица, и, не, расправляется, ,, рисунок, в, некоторых, местах, не, совпадает, ., ., еле, от, стены, отшкрябала, ,, в, полном, смысле, ., стена, новый, гипсокартон, ,, весь, в, краске, покрасилсяне, рекомендую, от, слова, совсем, !, !, !, !]</td>\n    </tr>\n    <tr>\n      <th>244738</th>\n      <td>248092</td>\n      <td>НЕ БЕРИТЕ!!!!! Мелкие, порезанные, подпорченные. Им цена 20 руб за всё. Отправлены в каком-то субстрате, пока не раскроешь, не увидишь какое там г... На ощупь не понять</td>\n      <td>там г...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[не, берите, !, !, !, !, !, мелкие, ,, порезанные, ,, подпорченные, ., им, цена, 20, руб, за, всё, ., отправлены, в, каком, -, то, субстрате, ,, пока, не, раскроешь, ,, не, увидишь, какое, там, г, ., ., ., на, ощупь, не, понять]</td>\n    </tr>\n  </tbody>\n</table>\n<p>34851 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# разбиение данные на треин и тест. Создание объектов Dataset\n\ndata_train, data_test = train_test_split(data.drop(['ID', 'text'], axis=1), test_size=0.2)\ndata_train.reset_index(drop=True, inplace=True)\ndata_test.reset_index(drop=True, inplace=True)\n\nner_data = DatasetDict({\n    'train': Dataset.from_pandas(data_train),\n    'test': Dataset.from_pandas(data_test)\n})\nner_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:54:34.754203Z","iopub.execute_input":"2025-01-18T14:54:34.754886Z","iopub.status.idle":"2025-01-18T14:54:36.631715Z","shell.execute_reply.started":"2025-01-18T14:54:34.754845Z","shell.execute_reply":"2025-01-18T14:54:36.630806Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'tags', 'tokens'],\n        num_rows: 195791\n    })\n    test: Dataset({\n        features: ['label', 'tags', 'tokens'],\n        num_rows: 48948\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_list = ['O', 'M']\ndef tokenize_and_align_labels(example: pd.DataFrame, label_all_tokens=True):\n    \"\"\"\n    Данная функция предназначена, чтобы создать столбцы \n    ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    предназначенные для обучения модели Bert\n    \"\"\"\n    tokenized_inputs = tokenizer(example['tokens'], truncation=True, is_split_into_words=True)\n    label = example['tags']\n    \n    if len(label) == 0:\n        tokenized_inputs['labels'] = []\n        return tokenized_inputs\n        \n    word_ids = tokenized_inputs.word_ids()\n    previous_word_idx = None\n    label_ids = []\n    \n    for word_idx in word_ids:\n        # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n        # ignored in the loss function.\n        if word_idx is None:\n            label_ids.append(-100)\n        # We set the label for the first token of each word.\n        elif word_idx != previous_word_idx:\n            #print(word_idx, 'word_idx')\n            label_ids.append(label[word_idx])\n        # For the other tokens in a word, we set the label to either the current label or -100, depending on\n        # the label_all_tokens flag.\n        else:\n            #print(word_idx, 'previous')\n            label_ids.append(label[word_idx] if label_all_tokens else -100)\n        previous_word_idx = word_idx\n\n    label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n    tokenized_inputs[\"labels\"] = label_ids\n    \n    return tokenized_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:54:36.632666Z","iopub.execute_input":"2025-01-18T14:54:36.632898Z","iopub.status.idle":"2025-01-18T14:54:36.642589Z","shell.execute_reply.started":"2025-01-18T14:54:36.632875Z","shell.execute_reply":"2025-01-18T14:54:36.641677Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# добавление необходимых столбцов и удаление ненужных для работы Bert\n\ntokenized_datasets = ner_data.map(tokenize_and_align_labels)\ntokenized_datasets = tokenized_datasets.remove_columns(['tags', 'tokens', 'label'])\ntokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:54:36.643540Z","iopub.execute_input":"2025-01-18T14:54:36.643835Z","iopub.status.idle":"2025-01-18T14:56:06.982632Z","shell.execute_reply.started":"2025-01-18T14:54:36.643811Z","shell.execute_reply":"2025-01-18T14:56:06.981624Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195791 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4656497ae5994e44a8322a8ed0b56790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48948 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26a07ae6385c41ed834cffe8bc662e0a"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 195791\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 48948\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"tokenized_datasets['train'][0]['attention_mask']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T12:48:41.726504Z","iopub.execute_input":"2025-01-18T12:48:41.726843Z","iopub.status.idle":"2025-01-18T12:48:41.735127Z","shell.execute_reply.started":"2025-01-18T12:48:41.726811Z","shell.execute_reply":"2025-01-18T12:48:41.733933Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"# загрузка предобученной модели\n\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\nmodel.config.id2label = dict(enumerate(label_list))\nmodel.config.label2id = {v: k for k, v in model.config.id2label.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:56:42.574424Z","iopub.execute_input":"2025-01-18T14:56:42.575340Z","iopub.status.idle":"2025-01-18T14:56:43.262486Z","shell.execute_reply.started":"2025-01-18T14:56:42.575302Z","shell.execute_reply":"2025-01-18T14:56:43.261819Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd9e8e01553481787c8e6f208e8108c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def compute_metrics(p, **kwargs):\n    \"\"\"\n    Данная функция предназначена для подсчета метрик на тестовой выборке при\n    обучении модели. Так же результы логируются в clearml\n    \"\"\"\n    predictions, labels = p.predictions, p.label_ids\n    input_ids = p.inputs\n    predictions = np.argmax(predictions, axis=2)\n    \n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    tp, fp, tn, fn = 0, 0, 0, 0\n    \n    for i in range(len(true_predictions)):\n        for j in range(len(true_predictions[i])):\n            if true_predictions[i][j] == true_labels[i][j] == 'M':\n                tp += 1\n            if true_predictions[i][j] == true_labels[i][j] == 'O':\n                tn += 1\n            if true_predictions[i][j] == 'O' and true_labels[i][j] == 'M':\n                fn += 1\n            if true_predictions[i][j] == 'M' and true_labels[i][j] == 'O':\n                fp += 1\n                \n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    \n    try:\n        recall = tp / (tp + fn)\n    except:\n        recall = 0\n    try:\n        precision = tp / (tp + fp)\n    except:\n        precision = 0\n    try:\n        f1 = 2 * recall * precision / (recall + precision)\n    except: f1 = 0\n        \n    task.get_logger().report_scalar(title='Metrics', series='accuracy', value=accuracy, iteration=trainer.state.global_step)\n    task.get_logger().report_scalar(title='Metrics', series='precision', value=precision, iteration=trainer.state.global_step)\n    task.get_logger().report_scalar(title='Metrics', series='recall', value=recall, iteration=trainer.state.global_step)\n    task.get_logger().report_scalar(title='Metrics', series='f1', value=f1, iteration=trainer.state.global_step)\n    \n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"accuracy\": accuracy,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:56:48.415773Z","iopub.execute_input":"2025-01-18T14:56:48.416547Z","iopub.status.idle":"2025-01-18T14:56:48.426545Z","shell.execute_reply.started":"2025-01-18T14:56:48.416506Z","shell.execute_reply":"2025-01-18T14:56:48.425757Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# создание эксперермента в clearml\ntask = Task.init(project_name='wb sprint2', task_name='rubert-tiny any M label in tokens 2 TEST2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:56:06.995890Z","iopub.execute_input":"2025-01-18T14:56:06.996234Z","iopub.status.idle":"2025-01-18T14:56:08.809318Z","shell.execute_reply.started":"2025-01-18T14:56:06.996198Z","shell.execute_reply":"2025-01-18T14:56:08.807826Z"}},"outputs":[{"name":"stdout","text":"ClearML Task: created new task id=3de5509697c54b6f9926fc7713afc5f1\n2025-01-18 14:56:08,062 - clearml.Repository Detection - WARNING - Jupyter Notebook auto-logging failed, could not access: /kaggle/working/__notebook_source__.ipynb\n2025-01-18 14:56:08,068 - clearml.Task - INFO - Storing jupyter notebook directly as code\nClearML results page: https://app.clear.ml/projects/ac60ac97556c43978ea64418f728663a/experiments/3de5509697c54b6f9926fc7713afc5f1/output/log\n2025-01-18 14:56:08,598 - clearml.log - WARNING - Event reporting sub-process lost, switching to thread based reporting\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/clearml/utilities/process/mp.py:633: RuntimeWarning:\n\nos.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"ClearML results page: https://app.clear.ml/projects/ac60ac97556c43978ea64418f728663a/experiments/3de5509697c54b6f9926fc7713afc5f1/output/log\n2025-01-18 15:48:57,494 - clearml.storage - INFO - Uploading: 44.62MB to /kaggle/working/model_rubert.pth\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/clearml/utilities/process/mp.py:633: RuntimeWarning:\n\nos.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n\n██████████████████████████████▉ 100% | 44.62/44.62 MB [00:00<00:00, 72.53MB/s]: \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Обучение модели Bert\n\nfor param in model.parameters():\n    param.requires_grad = True\n\n\nbatch_size = 32\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\nargs = TrainingArguments(\n    \"ner\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=8,\n    weight_decay=0.01,\n    save_strategy='no',\n    logging_steps=10,\n    report_to=[\"clearml\"]\n)\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T14:57:00.065557Z","iopub.execute_input":"2025-01-18T14:57:00.065872Z","iopub.status.idle":"2025-01-18T15:38:22.970751Z","shell.execute_reply.started":"2025-01-18T14:57:00.065847Z","shell.execute_reply":"2025-01-18T15:38:22.969924Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning:\n\n`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n\n","output_type":"stream"},{"name":"stdout","text":"2025-01-18 14:57:01,269 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers/accelerator_config[AcceleratorConfig])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='48952' max='48952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [48952/48952 41:19, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.006400</td>\n      <td>0.006726</td>\n      <td>0.917207</td>\n      <td>0.904859</td>\n      <td>0.910991</td>\n      <td>0.998031</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.004500</td>\n      <td>0.005360</td>\n      <td>0.907115</td>\n      <td>0.951242</td>\n      <td>0.928654</td>\n      <td>0.998372</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.002000</td>\n      <td>0.004459</td>\n      <td>0.922628</td>\n      <td>0.957124</td>\n      <td>0.939560</td>\n      <td>0.998629</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.004700</td>\n      <td>0.004324</td>\n      <td>0.918023</td>\n      <td>0.966627</td>\n      <td>0.941698</td>\n      <td>0.998667</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.001100</td>\n      <td>0.003974</td>\n      <td>0.927457</td>\n      <td>0.964704</td>\n      <td>0.945714</td>\n      <td>0.998767</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.005400</td>\n      <td>0.003862</td>\n      <td>0.933359</td>\n      <td>0.964138</td>\n      <td>0.948499</td>\n      <td>0.998834</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.003200</td>\n      <td>0.003869</td>\n      <td>0.929844</td>\n      <td>0.968607</td>\n      <td>0.948829</td>\n      <td>0.998837</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.002500</td>\n      <td>0.003843</td>\n      <td>0.931863</td>\n      <td>0.967758</td>\n      <td>0.949471</td>\n      <td>0.998853</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=48952, training_loss=0.005786239095421114, metrics={'train_runtime': 2481.6937, 'train_samples_per_second': 631.153, 'train_steps_per_second': 19.725, 'total_flos': 3759313013509428.0, 'train_loss': 0.005786239095421114, 'epoch': 8.0})"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# загрузка модели из предыдущих эксперементов\n\n# previous_task_id = '104bc56cbbf048bf8368bf9f60fe732f'  # Замените на ID вашего предыдущего эксперимента\n# previous_task = Task.get_task(task_id=previous_task_id)\n# model_artifact = previous_task.artifacts['model']\n# model_path = model_artifact.get_local_copy()\n\n# model = joblib.load(model_path)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-18T14:48:47.243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model_path) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T12:32:01.908949Z","iopub.execute_input":"2025-01-18T12:32:01.909359Z","iopub.status.idle":"2025-01-18T12:32:01.914822Z","shell.execute_reply.started":"2025-01-18T12:32:01.909325Z","shell.execute_reply":"2025-01-18T12:32:01.913793Z"}},"outputs":[{"name":"stdout","text":"/root/.clearml/cache/storage_manager/global/8ce16e0fef1c1dcd1990ac224bdb1744.topic_saved_weights.pth\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# подсчет расстояния Ливенштейна для обученной модели\n\ndistance = 0\ndistance_mat = 0\nk = 0\ncount_mat = 0\n\nfor i, row in tqdm(data_test.iterrows(), unit_scale=True):\n    try:\n        label = row['label'] if row['label'] is not np.nan else ''\n        text = ' '.join(row['tokens'])\n        tokens = tokenizer(text, return_tensors='pt')\n        tokens = {k: v.to(model.device) for k, v in tokens.items()}\n        with torch.no_grad():\n            pred = model(**tokens)\n            \n        words = []\n        labels = []\n        current_word = []\n        current_label = None\n        indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n        token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n        \n        for t, idx in zip(token_text, indices):\n            if t.startswith(\"##\"):\n                current_word.append(t[2:])\n                if idx == 'M':\n                    curent_label = idx\n            else:\n                if current_word:\n                    words.append(\"\".join(current_word))\n                    labels.append(current_label)\n                current_word = [t]\n                current_label = idx\n        \n        # Добавление последнего слова и метки\n        if current_word:\n            words.append(\"\".join(current_word))\n            labels.append(current_label)\n            \n        mats = []\n        \n        for word, label in zip(words, labels):\n            if label_list[label] == 'M':\n                mats.append(word)\n                \n        sorted(mats)\n        predict = \",\".join(mats)\n        label = row['label'] if row['label'] is not np.nan else ''\n        current_distance = Levenshtein.distance(predict, label)\n        distance += current_distance\n    \n        if row['label'] is not np.nan:\n            current_distance_mat = Levenshtein.distance(predict, label)\n            distance_mat += current_distance_mat\n            count_mat += 1\n            \n    except:\n        k += 1\n        continue\n\nmean_distance = distance / (len(data_test) - k)\nmean_distance_mat = distance_mat / count_mat\n\nprint(f\"Среднее расстояние Леветштейна: {mean_distance}\")\nprint(f\"Среднее расстояние Леветштейна для непустых label: {mean_distance_mat}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T15:38:54.667439Z","iopub.execute_input":"2025-01-18T15:38:54.667766Z","iopub.status.idle":"2025-01-18T15:41:41.317175Z","shell.execute_reply.started":"2025-01-18T15:38:54.667738Z","shell.execute_reply":"2025-01-18T15:41:41.316282Z"}},"outputs":[{"name":"stderr","text":"48.9kit [02:46, 294it/s]","output_type":"stream"},{"name":"stdout","text":"Среднее расстояние Леветштейна: 0.3943518064410659\nСреднее расстояние Леветштейна для непустых label: 2.649002849002849\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"При обучении модели мы видим, что recall выше precision. При этом наш метод с BPE имеет тоже хороший отклик. А что, если сделать ансамбль из двух моделей, где первая будет выдавать свою метку на основе BERT, а вторая будет смотреть, содержит слово патерн из BPE","metadata":{}},{"cell_type":"code","source":"# подсчет расстояния Ливенштейна для обученной модели используя ансамбль модели\n\ndistance = 0\ndistance_mat = 0\nk = 0\ncount_mat = 0\n\nfor i, row in tqdm(data_test.iterrows(), unit_scale=True):\n    try:\n        label = row['label'] if row['label'] is not np.nan else ''\n        text = ' '.join(row['tokens'])\n        tokens = tokenizer(text, return_tensors='pt')\n        tokens = {k: v.to(model.device) for k, v in tokens.items()}\n        with torch.no_grad():\n            pred = model(**tokens)\n            \n        words = []\n        labels = []\n        current_word = []\n        current_label = None\n        indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n        token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n        \n        for t, idx in zip(token_text, indices):\n            if t.startswith(\"##\"):\n                current_word.append(t[2:])\n                if idx == 'M':\n                    curent_label = idx\n            else:\n                if current_word:\n                    words.append(\"\".join(current_word))\n                    labels.append(current_label)\n                current_word = [t]\n                current_label = idx\n        \n        # Добавление последнего слова и метки\n        if current_word:\n            words.append(\"\".join(current_word))\n            labels.append(current_label)\n            \n        mats = []\n        \n        for word, label in zip(words, labels):\n            if label_list[label] == 'M':\n                 for pattern in filtred_vocab:\n                    if pattern in word:\n                        mats.append(word)\n                        break\n                \n        sorted(mats)\n        predict = \",\".join(mats)\n        label = row['label'] if row['label'] is not np.nan else ''\n        current_distance = Levenshtein.distance(predict, label)\n        distance += current_distance\n    \n        if row['label'] is not np.nan:\n            current_distance_mat = Levenshtein.distance(predict, label)\n            distance_mat += current_distance_mat\n            count_mat += 1\n            \n    except:\n        k += 1\n        continue\n\nmean_distance = distance / (len(data_test) - k)\nmean_distance_mat = distance_mat / count_mat\n\nprint(f\"Среднее расстояние Леветштейна: {mean_distance}\")\nprint(f\"Среднее расстояние Леветштейна для непустых label: {mean_distance_mat}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:16:16.536139Z","iopub.execute_input":"2025-01-18T16:16:16.536517Z","iopub.status.idle":"2025-01-18T16:19:02.237365Z","shell.execute_reply.started":"2025-01-18T16:16:16.536478Z","shell.execute_reply":"2025-01-18T16:19:02.236477Z"}},"outputs":[{"name":"stderr","text":"48.9kit [02:45, 295it/s]","output_type":"stream"},{"name":"stdout","text":"Среднее расстояние Леветштейна: 0.19320717872419566\nСреднее расстояние Леветштейна для непустых label: 6.897095435684648\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# task.connect({\n#     'mean_distance': mean_distance,\n#     'mean_distance_mat': mean_distance_mat,\n# })\n# model_path = '/kaggle/working/model_rubert.pth'\n# joblib.dump(model, 'model_rubert.pth', protocol=4)\n# Загрузка модели в ClearML\ntask.upload_artifact(name='model_rubert1', artifact_object=\"model_rubert.pth\")\ntask.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T15:48:53.198745Z","iopub.execute_input":"2025-01-18T15:48:53.199551Z","iopub.status.idle":"2025-01-18T15:58:46.117050Z","shell.execute_reply.started":"2025-01-18T15:48:53.199507Z","shell.execute_reply":"2025-01-18T15:58:46.115694Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# task.connect({\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     'mean_distance': mean_distance,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     'mean_distance_mat': mean_distance_mat,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# joblib.dump(model, 'model_rubert.pth', protocol=4)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Загрузка модели в ClearML\u001b[39;00m\n\u001b[1;32m      8\u001b[0m task\u001b[38;5;241m.\u001b[39mupload_artifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_rubert1\u001b[39m\u001b[38;5;124m'\u001b[39m, artifact_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_rubert.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/clearml/task.py:2472\u001b[0m, in \u001b[0;36mTask.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_subprocess():\n\u001b[1;32m   2470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_repo_detection(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300.\u001b[39m)\n\u001b[0;32m-> 2472\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__shutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;66;03m# unregister atexit callbacks and signal hooks, if we are the main task\u001b[39;00m\n\u001b[1;32m   2474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_main:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/clearml/task.py:4713\u001b[0m, in \u001b[0;36mTask.__shutdown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_at_exit_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sub_process \u001b[38;5;129;01mand\u001b[39;00m BackgroundMonitor\u001b[38;5;241m.\u001b[39mis_subprocess_enabled():\n\u001b[0;32m-> 4713\u001b[0m     \u001b[43mBackgroundMonitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_sub_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4715\u001b[0m \u001b[38;5;66;03m# we are done\u001b[39;00m\n\u001b[1;32m   4716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/clearml/utilities/process/mp.py:853\u001b[0m, in \u001b[0;36mBackgroundMonitor.wait_for_sub_process\u001b[0;34m(cls, task, timeout)\u001b[0m\n\u001b[1;32m    851\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mis_subprocess_alive(task\u001b[38;5;241m=\u001b[39mtask) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m timeout \u001b[38;5;129;01mor\u001b[39;00m time()\u001b[38;5;241m-\u001b[39mtic \u001b[38;5;241m<\u001b[39m timeout):\n\u001b[0;32m--> 853\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":36},{"cell_type":"code","source":"# tokens = []\n# for i, row in tqdm(test.iterrows(), unit_scale=True):\n#     prccessed_text = remove_emoji(row['text']).lower()\n#     raw_toks = tokenizer.tokenize(prccessed_text)\n#     words = []\n#     current_word = \"\"\n#     for token in raw_toks:\n#         if token.startswith(\"##\"):\n#             current_word += token[2:]\n#         else:\n#             if current_word:\n#                 words.append(current_word)\n#             current_word = token\n#     if current_word:\n#         words.append(current_word)\n#     tokens.append(words)\n    \n\n# test['tokens'] = tokens","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T22:20:44.957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:06:41.451138Z","iopub.execute_input":"2025-01-18T16:06:41.451370Z","iopub.status.idle":"2025-01-18T16:06:41.458479Z","shell.execute_reply.started":"2025-01-18T16:06:41.451347Z","shell.execute_reply":"2025-01-18T16:06:41.457606Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"{'...',\n '[UNK]',\n 'ано',\n 'ась',\n 'ать',\n 'аху',\n 'ахуе',\n 'ахуен',\n 'ахуенная',\n 'ахуенно',\n 'ахуенны',\n 'ахуенные',\n 'ахуенный',\n 'ахуй',\n 'бля',\n 'блять',\n 'блях',\n 'бляха',\n 'вать',\n 'вахуе',\n 'вно',\n 'вый',\n 'высер',\n 'г..',\n 'г...',\n 'г....',\n 'г.... г...',\n 'г.....',\n 'г..... г.... г...',\n 'г....о',\n 'г...но',\n 'г...о',\n 'г...о г...',\n 'гав',\n 'гавно',\n 'гавно гавно',\n 'гавно говно',\n 'гавно дерьмо',\n 'гавно херня',\n 'гамно',\n 'гов',\n 'говн',\n 'говна',\n 'говнище',\n 'говно',\n 'говно бл',\n 'говно бля',\n 'говно высер',\n 'говно гавно',\n 'говно говн',\n 'говно говно',\n 'говно дерьмо',\n 'говно еб',\n 'говно жоп',\n 'говно на',\n 'говно о',\n 'говно рукожоп',\n 'говно херня',\n 'говно хуйня',\n 'говном',\n 'гомно',\n 'дер',\n 'дермо',\n 'дерь',\n 'дерьм',\n 'дерьма',\n 'дерьмище',\n 'дерьмо',\n 'дерьмо гавно',\n 'дерьмо говно',\n 'дерьмо дерьмо',\n 'дерьмо херня',\n 'долб',\n 'еба',\n 'ебал',\n 'ебан',\n 'ебаная',\n 'ебу',\n 'ель',\n 'ень',\n 'жоп',\n 'жопа',\n 'жопе',\n 'жопу',\n 'жопы',\n 'зад',\n 'задниц',\n 'задница',\n 'заднице',\n 'задолб',\n 'задолбал',\n 'задолбалась',\n 'задолбали',\n 'заеб',\n 'заеба',\n 'заебись',\n 'заебок',\n 'залуп',\n 'залупа',\n 'збс',\n 'изд',\n 'ись',\n 'итель',\n 'ище',\n 'йня',\n 'конч',\n 'кончен',\n 'луп',\n 'мно',\n 'наеб',\n 'наебал',\n 'нахер',\n 'нахуй',\n 'ная',\n 'ндо',\n 'неебу',\n 'нихера',\n 'нихуя',\n 'ниц',\n 'нище',\n 'ное',\n 'нти',\n 'нтин',\n 'ные',\n 'ный',\n 'обос',\n 'ожоп',\n 'олб',\n 'оху',\n 'охуен',\n 'педи',\n 'пер',\n 'перд',\n 'пзд',\n 'пздц',\n 'пидо',\n 'пизд',\n 'пизда',\n 'пиздат',\n 'пиздатая',\n 'пиздато',\n 'пиздатые',\n 'пиздец',\n 'пизди',\n 'пиздили',\n 'пол',\n 'полное',\n 'про',\n 'проебал',\n 'раз',\n 'рал',\n 'рас',\n 'рук',\n 'рукожоп',\n 'рукожопы',\n 'сер',\n 'ски',\n 'сра',\n 'срал',\n 'сук',\n 'сука',\n 'суки',\n 'тая',\n 'тра',\n 'трах',\n 'х..',\n 'х...',\n 'хер',\n 'хера',\n 'херню',\n 'херня',\n 'херня гавно',\n 'херня говно',\n 'херня дерьмо',\n 'херня херня',\n 'херо',\n 'херь',\n 'хуе',\n 'хует',\n 'хуета',\n 'хуи',\n 'хуй',\n 'хуйня',\n 'хули',\n 'хулиг',\n 'хулиган',\n 'хуя',\n 'чмо',\n 'ъеб'}"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# предсказание на тестовых данных \n\npredictions = []\n\nfor i, row in tqdm(test.iterrows(), unit_scale=True):\n    try:\n        label = row['label'] if row['label'] is not np.nan else ''\n        text = row['text']\n        tokens = tokenizer(text, return_tensors='pt')\n        tokens = {k: v.to(model.device) for k, v in tokens.items()}\n        with torch.no_grad():\n            pred = model(**tokens)\n        words = []\n        labels = []\n        current_word = []\n        current_label = None\n        indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n        token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n        for t, idx in zip(token_text, indices):\n            if t.startswith(\"##\"):\n                current_word.append(t[2:])\n                if idx == 'M':\n                    curent_label = idx\n            else:\n                if current_word:\n                    words.append(\"\".join(current_word))\n                    labels.append(current_label)\n                current_word = [t]\n                current_label = idx\n        \n        # Добавление последнего слова и метки\n        if current_word:\n            words.append(\"\".join(current_word))\n            labels.append(current_label)\n        mats = []\n        for word, label in zip(words, labels):\n            if label_list[label] == 'M':\n                for pattern in filtered_vocab:\n                    if pattern in word:\n                        mats.append(word)\n                        break\n        sorted(mats)\n        predict = \",\".join(mats)\n        if predict == '':\n             predictions.append(np.nan)\n        else:\n            predictions.append(predict)\n    except:\n        predictions.append(np.nan)\n        continue\n\ntest['label'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:47:17.036497Z","iopub.execute_input":"2025-01-18T16:47:17.037221Z","iopub.status.idle":"2025-01-18T16:51:03.775644Z","shell.execute_reply.started":"2025-01-18T16:47:17.037188Z","shell.execute_reply":"2025-01-18T16:51:03.774676Z"}},"outputs":[{"name":"stderr","text":"66.9kit [03:46, 295it/s]\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:53:22.109726Z","iopub.execute_input":"2025-01-18T16:53:22.110469Z","iopub.status.idle":"2025-01-18T16:53:22.121563Z","shell.execute_reply.started":"2025-01-18T16:53:22.110435Z","shell.execute_reply":"2025-01-18T16:53:22.120645Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"          ID  \\\n0          0   \n1          1   \n2          2   \n3          3   \n4          4   \n...      ...   \n66944  71995   \n66945  71996   \n66946  71997   \n66947  71998   \n66948  71999   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n0                                                                                                                                                                                                                                                                                                                                                                                                                                  хороший, подошкл   \n1                                                                                                                                                                                                                                                                                                                                                                         совсем тонюсенький саженец, не досмотрела в описании,  что он годовалый:(   \n2                                                                                                                                                                                                                                                                                                                           когтеточка хорошая, но вот ткань на основании плохо приклеяна, пришлось доделывать чтоб мех не столз. кошаки осваивают.   \n3                                                                                                                                                                                                                                                                                                                                                                                                              много затяжек, не порадовала покупка   \n4                                                                                                                                                                                                                                                                                                                                                                                                                                      рекомендую 💣   \n...                                                                                                                                                                                                                                                                                                                                                                                                                                             ...   \n66944                                                                                                                                                                                                                                                                                                           Пачка как пачка а внутри совсем другое  \\nНекторве мелкие , почти как напалечник \\nВ пачке из трех один более мение \\nВообщем говно   \n66945                                                                                                                                                                                      Отвратительное качество!!! Через год тряпка, у супруга есть разных производителей нижнее белье, которое и по 3-5лет в приличном состоянии остаётся), но это просто швах!!!!! Продавец, имейте совесть, за такие деньги такое г… о!! Ну прям не честно!!!   \n66946                                                                                                                                                                                                                                                                                                                                                                                     Вес 100гр, не понимаю откуда хорошие отзывы , полное г...   \n66947  Приобрел и установил радиатор год назад , автомобиль практически не выезжал , летом заметил подтёки подумал что патрубок капает , но оказалось течет сам радиатор , до этого стоял такой же отработал лет 8 без проблем \\nКачество стало полное говно к покупке не рекомендую лучше взять что-то лучше в идеале медный , но там ценник конский \\nПроизводителю хочется пожелать здоровья и таких же качественных запчастей на его автомобиль   \n66948                                                                                                                                                                                                                                                                                                                                                                                                               заебись ручка, правда не пишет(   \n\n         label  \n0          NaN  \n1          NaN  \n2          NaN  \n3          NaN  \n4          NaN  \n...        ...  \n66944    говно  \n66945      NaN  \n66946      NaN  \n66947    говно  \n66948  заебись  \n\n[66949 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>хороший, подошкл</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>совсем тонюсенький саженец, не досмотрела в описании,  что он годовалый:(</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>когтеточка хорошая, но вот ткань на основании плохо приклеяна, пришлось доделывать чтоб мех не столз. кошаки осваивают.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>много затяжек, не порадовала покупка</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>рекомендую 💣</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66944</th>\n      <td>71995</td>\n      <td>Пачка как пачка а внутри совсем другое  \\nНекторве мелкие , почти как напалечник \\nВ пачке из трех один более мение \\nВообщем говно</td>\n      <td>говно</td>\n    </tr>\n    <tr>\n      <th>66945</th>\n      <td>71996</td>\n      <td>Отвратительное качество!!! Через год тряпка, у супруга есть разных производителей нижнее белье, которое и по 3-5лет в приличном состоянии остаётся), но это просто швах!!!!! Продавец, имейте совесть, за такие деньги такое г… о!! Ну прям не честно!!!</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>66946</th>\n      <td>71997</td>\n      <td>Вес 100гр, не понимаю откуда хорошие отзывы , полное г...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>66947</th>\n      <td>71998</td>\n      <td>Приобрел и установил радиатор год назад , автомобиль практически не выезжал , летом заметил подтёки подумал что патрубок капает , но оказалось течет сам радиатор , до этого стоял такой же отработал лет 8 без проблем \\nКачество стало полное говно к покупке не рекомендую лучше взять что-то лучше в идеале медный , но там ценник конский \\nПроизводителю хочется пожелать здоровья и таких же качественных запчастей на его автомобиль</td>\n      <td>говно</td>\n    </tr>\n    <tr>\n      <th>66948</th>\n      <td>71999</td>\n      <td>заебись ручка, правда не пишет(</td>\n      <td>заебись</td>\n    </tr>\n  </tbody>\n</table>\n<p>66949 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"test[['ID', 'label']].to_csv('answer12-ansambl.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-18T16:54:40.971425Z","iopub.execute_input":"2025-01-18T16:54:40.972174Z","iopub.status.idle":"2025-01-18T16:54:41.021325Z","shell.execute_reply.started":"2025-01-18T16:54:40.972137Z","shell.execute_reply":"2025-01-18T16:54:41.020072Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T22:20:44.957Z"}},"outputs":[],"execution_count":null}]}
